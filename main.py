import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
import pandas as pd
import numpy as np

import streamlit as st
import os
import base64

import streamlit as st
import base64
import os

audio_file_path = r"C:\Users\flux304\Downloads\relaxing-piano-310597.mp3"

if os.path.exists(audio_file_path):
    with open(audio_file_path, "rb") as f:
        audio_bytes = f.read()
        b64 = base64.b64encode(audio_bytes).decode()

    # ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ ì˜¤ë””ì˜¤ê°€ ì¬ìƒë˜ë„ë¡ í•©ë‹ˆë‹¤.
    if st.button("ğŸµ ë°°ê²½ ìŒì•… ì¬ìƒ"):
        st.markdown(
            f"""
            <audio autoplay loop controls style="display: none;">
                <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
            """,
            unsafe_allow_html=True
        )
        st.info("ğŸµ ë°°ê²½ ìŒì•…ì´ ì¬ìƒ ì¤‘ì…ë‹ˆë‹¤.")

else:
    st.error(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}")

    import streamlit as st
import base64

# ê°„ë‹¨í•œ ë°°ê²½ ì„¤ì • í•¨ìˆ˜
def set_jpg_background(image_path="background.jpg"):
    """JPG íŒŒì¼ì„ 50% íˆ¬ëª…ë„ë¡œ ë°°ê²½ ì„¤ì •"""
    
    with open(image_path, "rb") as f:
        img_str = base64.b64encode(f.read()).decode()
    
    st.markdown(f"""
    <style>
    .stApp {{
        background: linear-gradient(rgba(255,255,255,0.5), rgba(255,255,255,0.5)), 
                   url(data:image/jpeg;base64,{img_str});
        background-size: cover;
        background-position: center;
    }}
    </style>
    """, unsafe_allow_html=True)

# ì‚¬ìš©ë²•
set_jpg_background(r"C:\Users\flux304\Desktop\asd\ba.jpg")  # JPG íŒŒì¼ ê²½ë¡œ ì…ë ¥


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv('eed.env')

# API í‚¤ í™•ì¸
api_key = os.getenv('OPENAI_API_KEY')
if not api_key:
    st.error("âŒ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. eed.env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ ì •ì˜
FAISS_INDEX_DIR = "faiss_index"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬ë¦¬ì™€ MBTI ì „ë¬¸ AI ìƒë‹´ì‚¬ - RAG ê¸°ë°˜",
    page_icon="",
    layout="wide"
)

# MBTI ìœ í˜•ë³„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼ ì •ì˜ (8ê°€ì§€ ì „ì²´)
MBTI_STYLES = {
    "INTJ": {
        "style": "ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ì„¤ëª…ì„ ì„ í˜¸í•©ë‹ˆë‹¤. í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ê³  ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "tone": "ì „ë¬¸ì ì´ê³  ë¶„ì„ì ì¸ í†¤",
        "approach": "ë°ì´í„°ì™€ ë…¼ë¦¬ì— ê¸°ë°˜í•œ í•´ê²°ì±… ì œì‹œ",
        "keywords": ["ë…¼ë¦¬ì ", "ì²´ê³„ì ", "ë¶„ì„", "íš¨ìœ¨", "ê³„íš"]
    },
    "ENFP": {
        "style": "ì°½ì˜ì ì´ê³  ì—´ì •ì ì¸ ì ‘ê·¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ê°€ëŠ¥ì„±ì„ í•¨ê»˜ íƒêµ¬í•´ë³´ê² ìŠµë‹ˆë‹¤.",
        "tone": "ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤",
        "approach": "ë¸Œë ˆì¸ìŠ¤í† ë°ê³¼ ê°ì •ì  ì§€ì§€ ì œê³µ",
        "keywords": ["ì°½ì˜ì ", "ì•„ì´ë””ì–´", "ê°€ëŠ¥ì„±", "ì—´ì •", "ì˜ê°"]
    },
    "ISTJ": {
        "style": "ëª…í™•í•˜ê³  ì§ì„¤ì ì¸ ì†Œí†µì„ ì„ í˜¸í•©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì ˆì°¨ì™€ ë°©ë²•ì„ ì œì‹œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "tone": "ì •ì¤‘í•˜ê³  ì²´ê³„ì ì¸ í†¤",
        "approach": "ë‹¨ê³„ë³„ ê°€ì´ë“œì™€ ì‹¤ìš©ì  í•´ê²°ì±…",
        "keywords": ["ì²´ê³„ì ", "ì ˆì°¨", "ê·œì¹™", "ë‹¨ê³„", "ì •í™•"]
    },
    "ESFJ": {
        "style": "ë”°ëœ»í•˜ê³  ë°°ë ¤ ê¹Šì€ ì†Œí†µì„ ì„ í˜¸í•©ë‹ˆë‹¤. ê·€í•˜ì˜ ê°ì •ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ì§€ì›í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "tone": "ê³µê°ì ì´ê³  ì§€ì§€ì ì¸ í†¤",
        "approach": "ê°ì •ì  ì¼€ì–´ì™€ ì¸ê°„ì  ì ‘ê·¼",
        "keywords": ["ê°ì •", "ì‚¬ëŒ", "ë°°ë ¤", "ë„ì›€", "ê´€ê³„"]
    },
    "ENTP": {
        "style": "í˜ì‹ ì ì´ê³  ìœ ì—°í•œ ì ‘ê·¼ì„ ì„ í˜¸í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ ë°”ë¼ë³´ë©° ì°½ì˜ì  í•´ê²°ì±…ì„ ëª¨ìƒ‰í•˜ê² ìŠµë‹ˆë‹¤.",
        "tone": "ì—­ë™ì ì´ê³  ë„ì „ì ì¸ í†¤",
        "approach": "ì•„ì´ë””ì–´ ë°œì‚°ê³¼ ìƒˆë¡œìš´ ì‹œê° ì œê³µ",
        "keywords": ["í˜ì‹ ", "ë„ì „", "ìœ ì—°", "ë³€í™”", "ì‹¤í—˜"]
    },
    "ISFP": {
        "style": "ê°œì¸ì ì´ê³  ì§„ì •ì„± ìˆëŠ” ì†Œí†µì„ ì„ í˜¸í•©ë‹ˆë‹¤. ê·€í•˜ì˜ ê°œë³„ì  ìƒí™©ê³¼ ê°€ì¹˜ë¥¼ ì¡´ì¤‘í•˜ë©° ì ‘ê·¼í•˜ê² ìŠµë‹ˆë‹¤.",
        "tone": "ë”°ëœ»í•˜ê³  ê°œì¸ì ì¸ í†¤",
        "approach": "ê°œì¸ ë§ì¶¤í˜• ì¼€ì–´ì™€ ê°€ì¹˜ ì¤‘ì‹¬ í•´ê²°",
        "keywords": ["ê°œì¸ì ", "ì§„ì •ì„±", "ê°€ì¹˜", "ì˜ˆìˆ ", "ê°ì„±"]
    },
    "ESTJ": {
        "style": "íš¨ìœ¨ì ì´ê³  ì‹¤ìš©ì ì¸ ì†Œí†µì„ ì„ í˜¸í•©ë‹ˆë‹¤. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª…í™•í•œ í•´ê²°ì±…ì„ ì œì‹œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "tone": "ì§ì ‘ì ì´ê³  í™•ì‹¤í•œ í†¤",
        "approach": "ì¦‰ê°ì  í–‰ë™ê³¼ ê²°ê³¼ ì¤‘ì‹¬ í•´ê²°",
        "keywords": ["íš¨ìœ¨", "ì‹¤ìš©", "ë¹ ë¥¸", "ê²°ê³¼", "ì„±ì·¨", "ëª©í‘œ", "ë¦¬ë”ì‹­", "ì‹¤í–‰"]
    },
    "INFJ": {
        "style": "ê¹Šì´ ìˆê³  ì˜ë¯¸ ìˆëŠ” ì†Œí†µì„ ì„ í˜¸í•©ë‹ˆë‹¤. ê·¼ë³¸ì  ì›ì¸ì„ íŒŒì•…í•˜ì—¬ ì¥ê¸°ì  ê´€ì ì—ì„œ í•´ê²°í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
        "tone": "ì‹ ì¤‘í•˜ê³  í†µì°°ë ¥ ìˆëŠ” í†¤",
        "approach": "ë³¸ì§ˆì  ë¬¸ì œ í•´ê²°ê³¼ ë¯¸ë˜ ì§€í–¥ì  ì¡°ì–¸",
        "keywords": ["ê¹Šì´", "ì˜ë¯¸", "í†µì°°", "ë¯¸ë˜", "ì´í•´"]
    }
}

# ì‹¬ë¦¬í•™ ì „ë¬¸ ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ (RAGìš© ìƒ˜í”Œ ë°ì´í„°)
PSYCHOLOGY_KNOWLEDGE = """
MBTI ì‹¬ë¦¬í•™ ì „ë¬¸ ì§€ì‹ë² ì´ìŠ¤:

INTJ (ê±´ì¶•ê°€) ìœ í˜• íŠ¹ì„±:
- ë…ë¦½ì ì´ê³  ì°½ì¡°ì ì¸ ì‚¬ê³ ë¥¼ ê°€ì§„ ì™„ë²½ì£¼ì˜ì
- ì¥ê¸°ì  ê³„íšê³¼ ì „ëµì  ì‚¬ê³ ì— ë›°ì–´ë‚¨ Â 
- ìŠ¤íŠ¸ë ˆìŠ¤ ìƒí™©ì—ì„œëŠ” í˜¼ìë§Œì˜ ì‹œê°„ì´ í•„ìš”
- ë¶ˆë§Œ í•´ê²° ì‹œ ë…¼ë¦¬ì  ê·¼ê±°ì™€ ì²´ê³„ì  ì ‘ê·¼ì„ ì„ í˜¸
- ê°ì •ë³´ë‹¤ëŠ” ì‚¬ì‹¤ê³¼ ë°ì´í„°ì— ê¸°ë°˜í•œ í•´ê²°ì±… ìš”êµ¬

ENFP (í™œë™ê°€) ìœ í˜• íŠ¹ì„±:
- ì—´ì •ì ì´ê³  ì°½ì˜ì ì¸ ì„±ê²©ì˜ ì†Œìœ ì
- ì‚¬ëŒë“¤ê³¼ì˜ ê´€ê³„ë¥¼ ì¤‘ìš”ì‹œí•˜ë©° ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚¨
- ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ê³¼ ì•„ì´ë””ì–´ì— í¥ë¯¸ë¥¼ ë³´ì„
- ë¶ˆë§Œ ìƒí™©ì—ì„œë„ ê¸ì •ì  í•´ê²°ì±…ì„ ëª¨ìƒ‰
- ê°œì¸ì  ê°€ì¹˜ê´€ì´ ì¡´ì¤‘ë°›ê¸°ë¥¼ ì›í•¨

ISTJ (ë…¼ë¦¬ì£¼ì˜ì) ìœ í˜• íŠ¹ì„±: Â 
- ì²´ê³„ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ê²©
- ê¸°ì¡´ ê·œì¹™ê³¼ ì ˆì°¨ë¥¼ ì¤‘ìš”ì‹œí•¨
- ì•ˆì •ì„±ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì„ ì„ í˜¸
- ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ í•´ê²° ë°©ë²•ì„ ì›í•¨
- ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ ì§„í–‰í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•¨

ESFJ (ì§‘ì •ê´€) ìœ í˜• íŠ¹ì„±:
- íƒ€ì¸ì„ ë•ê³  ì¡°í™”ë¥¼ ì´ë£¨ë ¤ëŠ” ì„±í–¥ì´ ê°•í•¨
- ê°ì •ì  ì§€ì§€ì™€ ê²©ë ¤ë¥¼ ì¤‘ìš”ì‹œí•¨ Â 
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë„ì›€ì„ ì„ í˜¸
- ê°œì¸ì  ê´€ì‹¬ê³¼ ë°°ë ¤ë¥¼ í†µí•œ í•´ê²° ë°©ì‹ ì„ í˜¸
- ê³µë™ì²´ì™€ ê´€ê³„ ì¤‘ì‹¬ì˜ ì ‘ê·¼ì„ ì›í•¨

ENTP (ë³€ë¡ ê°€) ìœ í˜• íŠ¹ì„±:
- í˜ì‹ ì ì´ê³  ìœ ì—°í•œ ì‚¬ê³ ë¥¼ ê°€ì§„ ì•„ì´ë””ì–´ë±…í¬
- ìƒˆë¡œìš´ ë„ì „ê³¼ ë³€í™”ë¥¼ ì¦ê¹€
- ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ ë°”ë¼ë´„
- ì°½ì˜ì ì´ê³  ë…ì°½ì ì¸ í•´ê²°ì±…ì„ ì„ í˜¸
- í† ë¡ ê³¼ ë¸Œë ˆì¸ìŠ¤í† ë°ì„ í†µí•œ ë¬¸ì œ í•´ê²°

ISFP (ëª¨í—˜ê°€) ìœ í˜• íŠ¹ì„±:
- ê°œì¸ì˜ ê°€ì¹˜ì™€ ì‹ ë…ì„ ì¤‘ìš”ì‹œí•˜ëŠ” ì˜ˆìˆ ê°€ ê¸°ì§ˆ
- ì§„ì •ì„±ê³¼ authenticityë¥¼ ì¶”êµ¬
- ê°œì¸ì ì´ê³  ë§ì¶¤í˜• ì ‘ê·¼ì„ ì„ í˜¸
- ê°ì •ì  ê³µê°ê³¼ ì´í•´ë¥¼ í†µí•œ ì†Œí†µ
- ìì‹ ë§Œì˜ ì†ë„ë¡œ ë¬¸ì œ í•´ê²° ì§„í–‰

ESTJ (ê²½ì˜ì) ìœ í˜• íŠ¹ì„±:
- ëª©í‘œ ì§€í–¥ì ì´ê³  ì‹¤ìš©ì ì¸ ë¦¬ë”ì‹­ ìŠ¤íƒ€ì¼
- íš¨ìœ¨ì„±ê³¼ ìƒì‚°ì„±ì„ ì¤‘ìš”ì‹œí•¨
- ëª…í™•í•œ ê³„íšê³¼ ì‹¤í–‰ì„ ì„ í˜¸
- ì¦‰ê°ì ì¸ í–‰ë™ê³¼ ê²°ê³¼ë¥¼ ì¤‘ì‹œ
- ì²´ê³„ì ì´ê³  ì¡°ì§ì ì¸ ì ‘ê·¼ ë°©ì‹

INFJ (ì˜¹í˜¸ì) ìœ í˜• íŠ¹ì„±:
- ê¹Šì´ ìˆëŠ” í†µì°°ë ¥ê³¼ ì§ê´€ì  ì´í•´ë ¥
- ì¥ê¸°ì  ë¹„ì „ê³¼ ì˜ë¯¸ ìˆëŠ” ëª©ì  ì¶”êµ¬
- ê·¼ë³¸ì  ì›ì¸ íŒŒì•…ê³¼ ë³¸ì§ˆì  í•´ê²°ì±… ì„ í˜¸
- ì‹ ì¤‘í•˜ê³  ì‚¬ë ¤ê¹Šì€ ì ‘ê·¼ ë°©ì‹
- ê°œì¸ì˜ ì„±ì¥ê³¼ ë°œë‹¬ì— ê´€ì‹¬

ì‹¬ë¦¬ ìƒë‹´ ê¸°ë²•:
1. ì ê·¹ì  ê²½ì²­: ê³ ê°ì˜ ë§ì„ ëê¹Œì§€ ë“¤ì–´ì£¼ê¸°
2. ê³µê°ì  ë°˜ì‘: ê³ ê°ì˜ ê°ì •ì„ ì´í•´í•˜ê³  ê³µê° í‘œí˜„
3. ëª…ë£Œí™”: ê³ ê°ì˜ ë¬¸ì œë¥¼ ëª…í™•íˆ ì •ë¦¬í•´ì£¼ê¸°
4. ì¬êµ¬ì„±: ë¬¸ì œë¥¼ ë‹¤ë¥¸ ê´€ì ì—ì„œ ë°”ë¼ë³´ë„ë¡ ë„ì›€
5. í•´ê²°ì±… íƒìƒ‰: í•¨ê»˜ ì‹¤í˜„ ê°€ëŠ¥í•œ í•´ê²°ë°©ì•ˆ ëª¨ìƒ‰

ìŠ¤íŠ¸ë ˆìŠ¤ ëŒ€ì²˜ ë°©ë²•:
- INTJ: í˜¼ìë§Œì˜ ì‹œê°„, ì²´ê³„ì  ê³„íš ìˆ˜ë¦½
- ENFP: ì‚¬íšŒì  ì§€ì§€, ì°½ì˜ì  í™œë™
- ISTJ: ì¼ìƒ ë£¨í‹´ ìœ ì§€, ë‹¨ê³„ì  ì ‘ê·¼
- ESFJ: íƒ€ì¸ê³¼ì˜ ëŒ€í™”, ì‹¤ì§ˆì  ë„ì›€
- ENTP: ìƒˆë¡œìš´ ë„ì „, ë‹¤ì–‘í•œ ì‹œê° íƒìƒ‰
- ISFP: ê°œì¸ì  ì„±ì°°, ì˜ˆìˆ ì  í‘œí˜„
- ESTJ: ëª©í‘œ ì„¤ì •, ì¦‰ê°ì  í–‰ë™
- INFJ: ê¹Šì´ ìˆëŠ” ì‚¬ê³ , ì˜ë¯¸ íƒêµ¬

ë¶ˆë§Œ ì²˜ë¦¬ ì‹¬ë¦¬í•™:
- ì²«ì¸ìƒì˜ ì¤‘ìš”ì„±: ì²˜ìŒ 3ë¶„ì´ ì „ì²´ ìƒë‹´ ë¶„ìœ„ê¸° ê²°ì •
- ê°ì • ì™„í™” ê¸°ë²•: ê³ ê°ì˜ ë¶€ì •ì  ê°ì •ì„ ë¨¼ì € ìˆ˜ìš©í•˜ê³  ì•ˆì •í™”
- í•´ê²° ì§€í–¥ì  ì ‘ê·¼: ë¬¸ì œ ì¤‘ì‹¬ì´ ì•„ë‹Œ í•´ê²°ì±… ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€í™” ì§„í–‰
- ë§ì¶¤í˜• ì»¤ë®¤ë‹ˆì¼€ì´ì…˜: ê°œì¸ì˜ ì„±ê²©ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì ‘ê·¼
- ì‹ ë¢° ê´€ê³„ êµ¬ì¶•: ì§€ì†ì ì¸ ê´€ì‹¬ê³¼ ì¼ê´€ëœ íƒœë„ ìœ ì§€
"""

# ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_vector_store():
    """ì‹¬ë¦¬í•™ ì „ë¬¸ ì§€ì‹ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ êµ¬ì¶•í•˜ê±°ë‚˜ ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        # ë²¡í„° ìŠ¤í† ì–´ ë””ë ‰í† ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸
        if os.path.exists(FAISS_INDEX_DIR):
            st.info("âœ… ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
            vector_store = FAISS.load_local(FAISS_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
            st.success("ğŸ‰ ë²¡í„° ìŠ¤í† ì–´ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            return vector_store
        else:
            st.info("ğŸ”„ ìƒˆ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
            # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,
                separators=["\n\n", "\n", ":", "-", " "]
            )
            
            # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
            chunks = text_splitter.split_text(PSYCHOLOGY_KNOWLEDGE)
            
            # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
            
            # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            vector_store = FAISS.from_texts(
                texts=chunks,
                embedding=embeddings,
                metadatas=[{"source": f"psychology_kb_chunk_{i}"} for i in range(len(chunks))]
            )
            
            # ë²¡í„° ìŠ¤í† ì–´ ì €ì¥
            vector_store.save_local(FAISS_INDEX_DIR)
            st.success("ğŸ‰ ìƒˆ ë²¡í„° ìŠ¤í† ì–´ê°€ ìƒì„± ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return vector_store
            
    except Exception as e:
        st.error(f"ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”/ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return None

# ì„±ê²© ë¶„ì„ í•¨ìˆ˜ (RAG ê¸°ë°˜ìœ¼ë¡œ ê°•í™”)
def analyze_personality_with_rag(user_input, vector_store):
    """RAGë¥¼ í™œìš©í•œ ê³ ë„í™”ëœ ì„±ê²© ë¶„ì„"""
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­
    for mbti_type, info in MBTI_STYLES.items():
        for keyword in info["keywords"]:
            if keyword in user_input:
                # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ í•´ë‹¹ MBTI ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
                if vector_store:
                    docs = vector_store.similarity_search(f"{mbti_type} íŠ¹ì„±", k=2)
                    context = "\n".join([doc.page_content for doc in docs])
                    return mbti_type, context
                return mbti_type, ""
    
    # ê³ ê¸‰ íŒ¨í„´ ë¶„ì„
    patterns = {
        "INTJ": ["ì™œ", "ì–´ë–»ê²Œ", "ë°©ë²•", "í•´ê²°", "ë¶„ì„", "ì‹œìŠ¤í…œ"],
        "ENFP": ["ëŠë‚Œ", "ìƒê°", "ì•„ì´ë””ì–´", "ê°€ëŠ¥ì„±", "í¥ë¯¸", "ì¬ë¯¸"],
        "ISTJ": ["ì ˆì°¨", "ë°©ë²•", "ë‹¨ê³„", "ì •í™•", "í™•ì‹¤", "ì•ˆì „"],
        "ESFJ": ["ê¸°ë¶„", "ë§ˆìŒ", "ì†ìƒ", "ë„ì™€", "ê´€ê³„", "ì‚¬ëŒë“¤"],
        "ENTP": ["ìƒˆë¡œìš´", "ë‹¤ë¥¸", "ë³€í™”", "ì‹¤í—˜", "ë„ì „", "í˜ì‹ "],
        "ISFP": ["ê°œì¸", "ë‚˜ë§Œ", "íŠ¹ë³„", "ì˜ë¯¸", "ê°€ì¹˜", "ì¤‘ìš”"],
        "ESTJ": ["ë¹¨ë¦¬", "ë°”ë¡œ", "ì¦‰ì‹œ", "íš¨ê³¼", "ê²°ê³¼", "ì„±ê³¼"],
        "INFJ": ["ì´í•´", "ê¹Šì´", "ë³¸ì§ˆ", "ë¯¸ë˜", "ì˜ë¯¸", "í†µì°°"]
    }
    
    for mbti_type, keywords in patterns.items():
        if any(word in user_input for word in keywords):
            if vector_store:
                docs = vector_store.similarity_search(f"{mbti_type} íŠ¹ì„±", k=2)
                context = "\n".join([doc.page_content for doc in docs])
                return mbti_type, context
            return mbti_type, ""
    
    return "ENFP", ""  # ê¸°ë³¸ê°’

# RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_rag_response(user_input, personality_type, vector_store, chat_history=None):
    """RAGë¥¼ í™œìš©í•œ ì „ë¬¸ì ì¸ ì‹¬ë¦¬ ìƒë‹´ ì‘ë‹µ ìƒì„±"""
    
    style_info = MBTI_STYLES.get(personality_type, MBTI_STYLES["ENFP"])
    
    # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    relevant_docs = ""
    if vector_store:
        # ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì„±ê²© ìœ í˜•ì— ê¸°ë°˜í•œ ê²€ìƒ‰
        search_query = f"{user_input} {personality_type} ìƒë‹´"
        docs = vector_store.similarity_search(search_query, k=3)
        relevant_docs = "\n".join([doc.page_content for doc in docs])
    
    # RAG ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    system_prompt = f"""ë‹¹ì‹ ì€ MBTI ì‹¬ë¦¬í•™ ì „ë¬¸ê°€ì´ì ê²½í—˜ì´ í’ë¶€í•œ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

[ê³ ê° ì„±ê²© ìœ í˜• ë¶„ì„]
- ì„±ê²© ìœ í˜•: {personality_type}
- ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼: {style_info['style']}
- ì„ í˜¸í•˜ëŠ” í†¤: {style_info['tone']}
- ì ‘ê·¼ ë°©ì‹: {style_info['approach']}

[ì „ë¬¸ ì‹¬ë¦¬í•™ ì§€ì‹ë² ì´ìŠ¤]
{relevant_docs}

[ìƒë‹´ ì§€ì¹¨]
1. ìœ„ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ì¡°ì–¸ ì œê³µ
2. ê³ ê°ì˜ ì„±ê²© ìœ í˜•ì— ìµœì í™”ëœ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼ ì‚¬ìš©
3. êµ¬ì²´ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ í•´ê²°ì±… ì œì‹œ
4. ê³µê°ê³¼ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë”°ëœ»í•œ ìƒë‹´
5. í•„ìš”ì‹œ ì „ë¬¸ì ì¸ ì‹¬ë¦¬í•™ ê°œë…ê³¼ ê¸°ë²• í™œìš©

í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

    if chat_history:
        messages = [("system", system_prompt)]
        for msg in chat_history[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ í¬í•¨
            messages.append((msg["role"], msg["content"]))
        messages.append(("human", "{input}"))
    else:
        messages = [
            ("system", system_prompt),
            ("human", "{input}")
        ]
    
    prompt_template = ChatPromptTemplate.from_messages(messages)
    return prompt_template

# íŒŒì¼ ì—…ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def update_vector_store_with_file(uploaded_file, vector_store):
    """ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ë²¡í„° ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸"""
    try:
        if uploaded_file.type == "application/pdf":
            # PDF ì²˜ë¦¬
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file_path = tmp_file.name
            
            loader = PyPDFLoader(tmp_file_path)
            documents = loader.load()
            
            # íŒŒì¼ ì •ë¦¬
            os.unlink(tmp_file_path)
            
        else:
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
            content = uploaded_file.read().decode("utf-8")
            documents = [{"page_content": content, "metadata": {"source": uploaded_file.name}}]
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        
        texts = []
        metadatas = []
        
        for doc in documents:
            chunks = text_splitter.split_text(doc.page_content if hasattr(doc, 'page_content') else doc["page_content"])
            texts.extend(chunks)
            metadatas.extend([{"source": uploaded_file.name + f"_chunk_{i}"} for i in range(len(chunks))])
        
        # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
        new_vectors = FAISS.from_texts(texts, embeddings, metadatas)
        
        # ë²¡í„° ìŠ¤í† ì–´ ë³‘í•©
        vector_store.merge_from(new_vectors)
        
        # ë³€ê²½ ì‚¬í•­ì„ íŒŒì¼ì— ì €ì¥
        vector_store.save_local(FAISS_INDEX_DIR)
        
        return True, f"{uploaded_file.name} íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        return False, f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ë©”ì¸ UI í•¨ìˆ˜
def main():
    st.title(" ì‹¬ë¦¬ì™€ MBTI ì „ë¬¸ AI ìƒë‹´ì‚¬ (RAG ê¸°ë°˜)")
    st.markdown("### ì „ë¬¸ ì‹¬ë¦¬í•™ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë§ì¶¤í˜• ìƒë‹´ ì„œë¹„ìŠ¤")
    st.markdown("---")
    
    # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (í•˜ë“œì—ì„œ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±)
    if "vector_store" not in st.session_state:
        with st.spinner("ì „ë¬¸ ì‹¬ë¦¬í•™ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ë¡œë”©ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state.vector_store = initialize_vector_store()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header(" ìƒë‹´ ìŠ¤íƒ€ì¼ ì„¤ì •")
        
        # íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
        st.subheader("ğŸ“„ ìë£Œ ì¶”ê°€")
        uploaded_file = st.file_uploader(
            "ì‹¬ë¦¬í•™ ë˜ëŠ” ìƒë‹´ìŠ¤íƒ€ì¼ ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF, TXT)",
            type=['pdf', 'txt'],
            help="ì—…ë¡œë“œí•œ ìë£ŒëŠ” ìƒë‹´ì— í™œìš©ë©ë‹ˆë‹¤"
        )
        
        if uploaded_file and st.button("ğŸ“¤ ë¬¸ì„œ ì¶”ê°€"):
            success, message = update_vector_store_with_file(uploaded_file, st.session_state.vector_store)
            if success:
                st.success(message)
            else:
                st.error(message)
        
        st.divider()
        
        # MBTI ìˆ˜ë™ ì„ íƒ
        mbti_type = st.selectbox(
            "MBTI ìœ í˜• ì„ íƒ:",
            ["ìë™ ë¶„ì„"] + list(MBTI_STYLES.keys()),
            help="ìë™ ë¶„ì„ì„ ì„ íƒí•˜ë©´ ëŒ€í™” ë‚´ìš©ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤"
        )
        
        # ìƒë‹´ ëª¨ë“œ ì„ íƒ
        counseling_mode = st.radio(
            "ìƒë‹´ ëª¨ë“œ:",
            ["ì¼ë°˜ ìƒë‹´", "ë¶ˆë§Œ ì²˜ë¦¬", "ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬", "ê´€ê³„ ìƒë‹´"],
            help="ìƒë‹´ ì£¼ì œì— ë”°ë¼ ì ‘ê·¼ ë°©ì‹ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤"
        )
        
        # í˜„ì¬ ê°ì§€ëœ ì„±ê²© ìœ í˜• í‘œì‹œ
        if "current_mbti" in st.session_state and "mbti_context" in st.session_state:
            st.success(f"ğŸ¯ ë¶„ì„ëœ ìœ í˜•: **{st.session_state.current_mbti}**")
            
            with st.expander("ğŸ“‹ ì„±ê²© ë¶„ì„ ì •ë³´"):
                style = MBTI_STYLES[st.session_state.current_mbti]
                st.write(f"**ìŠ¤íƒ€ì¼:** {style['style']}")
                st.write(f"**í†¤:** {style['tone']}")
                st.write(f"**ì ‘ê·¼ë²•:** {style['approach']}")
                
                if st.session_state.mbti_context:
                    st.write("**ì „ë¬¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„:**")
                    st.write(st.session_state.mbti_context[:200] + "...")
        
        # ëŒ€í™” ì´ˆê¸°í™”
        if st.button("ğŸ”„ ìƒë‹´ ì´ˆê¸°í™”"):
            st.session_state.messages = []
            if "current_mbti" in st.session_state:
                del st.session_state.current_mbti
            if "mbti_context" in st.session_state:
                del st.session_state.mbti_context
            st.rerun()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ì´ì „ ëŒ€í™” ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input := st.chat_input("ë§ˆìŒ í¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”..."):
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ì„±ê²© ìœ í˜• ë¶„ì„
        if mbti_type == "ìë™ ë¶„ì„":
            detected_type, context = analyze_personality_with_rag(
                user_input, 
                st.session_state.vector_store
            )
            st.session_state.current_mbti = detected_type
            st.session_state.mbti_context = context
        else:
            detected_type = mbti_type
            st.session_state.current_mbti = detected_type
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            try:
                # OpenAI ëª¨ë¸ ì´ˆê¸°í™”
                llm = ChatOpenAI(
                    temperature=0.7,
                    model="gpt-3.5-turbo",
                    max_tokens=1500
                )
                
                # RAG ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt_template = generate_rag_response(
                    user_input, 
                    detected_type, 
                    st.session_state.vector_store,
                    st.session_state.messages
                )
                
                # ì‘ë‹µ ìƒì„±
                with st.spinner("ì „ë¬¸ì ì¸ ìƒë‹´ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    chain = prompt_template | llm | StrOutputParser()
                    response = chain.invoke({"input": user_input})
                
                # ì „ë¬¸ì„± í‘œì‹œì™€ í•¨ê»˜ ì‘ë‹µ
                full_response = f"{response}\n\n---\n* **{detected_type} ìœ í˜• ë§ì¶¤ ìƒë‹´** | ğŸ“š ì „ë¬¸ ì‹¬ë¦¬í•™ ì§€ì‹ ê¸°ë°˜ | ğŸ¯ {counseling_mode} ëª¨ë“œ*"
                
                st.markdown(full_response)
                
                # ì‘ë‹µ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response
                })
                
            except Exception as e:
                st.error(f"âŒ ìƒë‹´ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ğŸ’¡ API í‚¤ ì„¤ì •ì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # í•˜ë‹¨ ì •ë³´ íŒ¨ë„
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        with st.expander("ğŸ” RAG ê¸°ë°˜ ì „ë¬¸ ìƒë‹´ì˜ íŠ¹ì§•"):
            st.markdown("""
            **ğŸ¯ ì „ë¬¸ì„± ê°•í™” ìš”ì†Œ:**
            - ì‹¬ë¦¬í•™ ì „ë¬¸ ì§€ì‹ë² ì´ìŠ¤ í™œìš©
            - MBTI ìœ í˜•ë³„ ë§ì¶¤ ìƒë‹´ ê¸°ë²•
            - ì‹¤ì‹œê°„ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            - ìƒí™©ë³„ ìµœì í™”ëœ ì¡°ì–¸ ì œê³µ
            
            **ğŸ“š ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤:**
            - MBTI 8ê°€ì§€ ìœ í˜• íŠ¹ì„± ë¶„ì„
            - ì‹¬ë¦¬ ìƒë‹´ ì „ë¬¸ ê¸°ë²• Â 
            - ìŠ¤íŠ¸ë ˆìŠ¤ ëŒ€ì²˜ ë°©ë²•ë¡ 
            - ë¶ˆë§Œ ì²˜ë¦¬ ì‹¬ë¦¬í•™ ì´ë¡ 
            """)
    
    with col2:
        with st.expander("ğŸ“– MBTI ìœ í˜•ë³„ ìƒë‹´ íŠ¹ì§•"):
            st.markdown("""
            **ğŸ§  ë¶„ì„ê°€í˜• (NT)**
            - INTJ: ë…¼ë¦¬ì  ì²´ê³„ì  ì ‘ê·¼
            - ENTP: í˜ì‹ ì  ìœ ì—°í•œ ì‚¬ê³ 
            
            **ğŸ­ ì™¸êµê´€í˜• (NF)** Â 
            - ENFP: ì°½ì˜ì  ì—´ì •ì  ì§€ì§€
            - INFJ: ê¹Šì´ìˆëŠ” í†µì°°ì  ì¡°ì–¸
            
            **âš–ï¸ ê´€ë¦¬ìí˜• (SJ)**
            - ISTJ: ëª…í™•í•œ ë‹¨ê³„ì  ê°€ì´ë“œ
            - ESFJ: ë”°ëœ»í•œ ê³µê°ì  ì¼€ì–´
            
            **ğŸ¨ íƒí—˜ê°€í˜• (SP)**
            - ESTJ: íš¨ìœ¨ì  ì‹¤ìš©ì  í•´ê²°
            - ISFP: ê°œì¸ì  ì§„ì •ì„±ìˆëŠ” ì§€ì§€
            """)

if __name__ == "__main__":
    main()